\subsection{Introduction}
This chapter outlines the comprehensive methodology employed to achieve the research objectives, focusing on the systematic approach to data preparation, model development, and evaluation. It details the steps taken to process the raw CIC-IDS2017 dataset, configure the XGBoost model, and establish a robust experimental setup for performance assessment. The aim is to ensure reproducibility and provide a clear understanding of the research design.

\subsection{Dataset Description: CIC-IDS2017}
The Canadian Institute for Cybersecurity (CIC) CIC-IDS2017 dataset was chosen for this study due to its realistic representation of modern network traffic, including both benign and various common attack scenarios. The dataset comprises network flow data captured over five days (Monday to Friday), with Monday representing normal activity and the subsequent days incorporating different types of attacks. It consists of over 2.8 million network flows, each characterized by 78 features extracted using CICFlowMeter, along with a 'Label' column indicating whether the flow is benign or malicious (and the specific attack type if malicious). The attacks covered include Brute Force FTP, Brute Force SSH, DoS (GoldenEye, Hulk, Slowhttptest, Slowloris), Heartbleed, Web Attack (Brute Force, XSS, Sql Injection), Infiltration, Botnet, and DDoS. The dataset is publicly available in CSV format, making it suitable for machine learning research.

\subsection{Data Pre-processing}
The quality and format of the raw dataset significantly impact model performance. The following steps were meticulously applied to prepare the CIC-IDS2017 dataset for the XGBoost algorithm:

\subsection{Data Loading and Initial Inspection}
The dataset, distributed across multiple CSV files (one for each day), was loaded into a Pandas DataFrame. Initial inspection involved checking data types, identifying non-numeric columns, and examining the first few rows to understand the structure. Features identified as redundant (e.g., 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags' which contain mostly zero values or are identical across samples) were noted for potential removal.

\subsection{Handling Missing and Infinite Values} The dataset was found to contain both missing values (NaN) and infinite values (Infinity) in several columns, particularly related to flow statistics (e.g., 'Flow Bytes/s', 'Flow Packets/s'). Infinite values were first replaced with NaN to unify missing data representation. Subsequently, missing values were imputed using the mean of their respective columns, a strategy chosen for its simplicity and effectiveness in preserving the overall distribution for this large dataset.

\subsection{Handling Categorical Features}
The 'Protocol' feature, being categorical, was converted into numerical format. One-Hot Encoding was applied to this feature to avoid imposing an artificial ordinal relationship, creating new binary columns for each protocol type (e.g., TCP, UDP, ICMP). The 'Label' column, representing the target variable (attack type or benign), was Label Encoded to convert string labels into numerical integers for multi-class classification.

\subsection{Feature Scaling/Normalization}
While tree-based models like XGBoost are less sensitive to feature scaling than distance-based algorithms, scaling can sometimes aid in regularization and convergence. Therefore, numerical features were scaled using StandardScaler from scikit-learn. This transforms the data to have a mean of 0 and a standard deviation of 1, which can prevent features with larger numerical ranges from dominating the learning process.

\subsection{Feature Engineering (if applicable)}
No new features were explicitly engineered beyond the original 78 features provided by CICFlowMeter. The focus was on leveraging the rich set of existing flow-based features.

\subsection{Handling Class Imbalance}
The CIC-IDS2017 dataset exhibits significant class imbalance, with the 'Benign' class being overwhelmingly dominant and some attack classes having very few instances. To mitigate this, the scale\textunderscore pos\textunderscore weight parameter in XGBoost was utilized. This parameter assigns a weight to the positive class in binary classification or to minority classes in multi-class classification, effectively penalizing misclassifications of the under-represented classes more heavily. The weights were calculated as the ratio of the number of negative samples to the number of positive samples for each attack class relative to the benign class. Additionally, for severe minority classes, a limited application of Synthetic Minority Over-sampling Technique (SMOTE) was considered for the training set, to generate synthetic samples for the smallest attack categories, ensuring the model has sufficient examples to learn from.

\subsection{Model Selection}
XGBoost (Extreme Gradient Boosting) was selected as the primary machine learning algorithm for this intrusion detection system. This choice is justified by XGBoost's proven capabilities in handling large, tabular datasets, its efficiency, scalability, and superior performance in numerous classification tasks. As a gradient boosting framework, it builds an ensemble of decision trees sequentially, correcting the errors of previous trees. Its built-in regularization techniques (L1 and L2) help prevent overfitting, and its ability to handle missing values and support parallel processing makes it highly suitable for the characteristics of the CIC-IDS2017 dataset.

\subsection{Experimental Setup}
The experimental setup was designed to ensure a rigorous and fair evaluation of the proposed NIDS.

\subsubsection{Data Splitting}
The pre-processed dataset was randomly split into training and testing sets with a 70\%-30\% ratio, respectively. To maintain the original class distribution in both sets, stratified sampling was applied. A separate validation set (e.g., 15\% of the training data) was optionally used during hyperparameter tuning to prevent data leakage from the final test set.

\subsubsection{Evaluation Metrics}
Given the highly imbalanced nature of the CIC-IDS2017 dataset, a comprehensive set of evaluation metrics was employed beyond simple accuracy:
\begin{itemize}
	\item Accuracy: Overall correctness of predictions.
	\item Precision: The proportion of true positive predictions among all positive predictions.
	\item  Recall (Sensitivity/Detection Rate): The proportion of true positive predictions among all actual positive instances. Crucial for NIDS to minimize false negatives (missed attacks).
	\item F1-Score: The harmonic mean of precision and recall, providing a balanced measure. Both macro-averaged (average F1-score per class) and weighted-averaged (F1-score weighted by the number of true instances for each label) F1-scores were reported to account for class imbalance.
	\item Confusion Matrix: A table visualizing the performance of the classification model, showing true positives, true negatives, false positives, and false negatives for each class.
	\item False Positive Rate (FPR) / False Alarm Rate (FAR): The proportion of benign instances incorrectly classified as malicious. Minimizing FPR is critical for practical NIDS deployment.
	\item True Positive Rate (TPR): Identical to Recall.
	\item ROC AUC Score and Precision-Recall Curves: Used to evaluate the model's ability to distinguish between classes across various thresholds, especially informative for imbalanced datasets.
\end{itemize}

\subsection{Tools and Environment}
All experiments were conducted using Python (version X.X) as the programming language. Key libraries included pandas for data manipulation, numpy for numerical operations, scikit-learn for pre-processing and evaluation tools, xgboost for the model implementation, and matplotlib and seaborn for data visualization. The experiments were performed on a machine with [mention CPU/GPU, RAM, e.g., Intel Core i7 processor, 16GB RAM, and NVIDIA GeForce RTX 3060 GPU].

\subsection{Hyperparameter Tuning}
To optimize the performance of the XGBoost model, a systematic hyperparameter tuning process was undertaken. Initially, a broad Randomized Search Cross-Validation (RandomizedSearchCV from scikit-learn) was performed to explore a wide range of parameter combinations efficiently. This was followed by a more focused Grid Search Cross-Validation (GridSearchCV) around the promising regions identified by the randomized search. The key hyperparameters tuned included:
\begin{itemize}
	\item n\textunderscore estimators: [e.g., 100, 200, 300, 500]
	\item learning\textunderscore rate: [e.g., 0.01, 0.05, 0.1, 0.2]
	\item max\textunderscore depth: [e.g., 3, 5, 7, 9]
	\item subsample: [e.g., 0.6, 0.8, 1.0]
	\item colsample\textunderscore bytree: [e.g., 0.6, 0.8, 1.0]
	\item gamma: [e.g., 0, 0.1, 0.2]
	\item reg\textunderscore alpha (L1 regularization): [e.g., 0, 0.001, 0.01]
	\item  reg\textunderscore lambda (L2 regularization): [e.g., 1, 10, 100]
	\item scale\textunderscore pos\textunderscore weight: Dynamically calculated based on class imbalance, or tuned for specific minority classes. The tuning process utilized 5-fold cross-validation on the training set, with the F1-score (macro-averaged) as the primary metric for selecting the best model, given its robustness to class imbalance.
\end{itemize}

\subsection{Comparative Analysis}
To contextualize the performance of the optimized XGBoost model, its results were compared against several other commonly used machine learning algorithms for NIDS. These algorithms included:
\begin{itemize}
	\item Random Forest (RF): Another ensemble tree-based method, known for its robustness and good performance.
	\item LightGBM: A gradient boosting framework developed by Microsoft that uses histogram-based algorithms and leaf-wise tree growth, enabling faster training and lower memory usage. It is particularly efficient for large-scale, high-dimensional datasets.
	\item CatBoost: A gradient boosting algorithm developed by Yandex that is optimized for categorical feature handling without extensive preprocessing. It uses ordered boosting and symmetric trees to reduce overfitting and improve generalization performance.
\end{itemize}

%\subsection{Ethical Considerations}